{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from imp import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import textwrap\n",
    "import random\n",
    "import json\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../noncomm_use_subset/pmc_json/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up files from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PMC1616946.xml.json', 'PMC1616953.xml.json', 'PMC1616970.xml.json', 'PMC1635287.xml.json', 'PMC1636417.xml.json']\n",
      "---------../noncomm_use_subset/pmc_json_test/PMC1616946.xml.json\n",
      "\n",
      "++---------../noncomm_use_subset/pmc_json_test/PMC1616946.xml.json\n",
      "++---------../noncomm_use_subset/pmc_json_test/PMC1616953.xml.json\n",
      "++---------../noncomm_use_subset/pmc_json_test/PMC1616970.xml.json\n",
      "++---------../noncomm_use_subset/pmc_json_test/PMC1635287.xml.json\n",
      "++---------../noncomm_use_subset/pmc_json_test/PMC1636417.xml.json\n",
      "@@@@@@\n",
      "\n",
      "\n",
      "30635\n",
      "@@@@@@\n",
      "\n",
      "\n",
      "48107\n",
      "@@@@@@\n",
      "\n",
      "\n",
      "25672\n",
      "@@@@@@\n",
      "\n",
      "\n",
      "44202\n",
      "@@@@@@\n",
      "\n",
      "\n",
      "60627\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../noncomm_use_subset/pmc_json_test/'\n",
    "filename = 'PMC1616946.xml.json'\n",
    "\n",
    "print(os.listdir(dir_path))\n",
    "\n",
    "print(\"---------\" + dir_path + filename)\n",
    "print()\n",
    "\n",
    "articles = []\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "    filepath = dir_path + file\n",
    "    print(\"++---------\" + filepath)\n",
    "    with open(filepath, 'r') as infile:\n",
    "        json_object = json.load(infile)\n",
    "        #print(json.dumps(json_object, indent=2))\n",
    "        a = Article(json_object)\n",
    "        articles.append(a)\n",
    "        \n",
    "# Check result        \n",
    "for a in articles:\n",
    "    print(\"@@@@@@\\n\\n\")\n",
    "    print(len(a.get_text()))\n",
    "    \n",
    "            #df = pd.read_json(infile,\n",
    "            #                 lines=True,\n",
    "            #                 orient='columns')\n",
    "    #df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"S.solfataricus cells were grown, and cell extracts obtained, as described previously (24,28). S.solfataricus cells were grown, and cell extracts obtained, as described previously (24,28). The expression in the E.coli strain BL21(RB791) of the wild-type gene fucA1 and of the mutant genes fucA1A [previously named FrameFuc in (24)], fucA1B, fucA1sm and fucA1tm as fusions of glutathione S-transferase (GST) and the purification of the recombinant proteins were performed as reported previously (23). The nomenclature used in this paper for the different α-fucosidase genes is listed in Table 1. For the western blot studies, equal amounts of E.coli cultures expressing the wild-type and mutant fucA1 genes, normalized for the OD600, were resuspended in SDS–PAGE loading buffer containing 0.03 M Tris–HCl buffer, pH 6.8, 3% SDS (w/v), 6.7% glycerol (w/v), 6.7% 2-mercaptoethanol (w/v) and 0.002% blue bromophenol (w/v). The samples were incubated at 100°C for 5 min (unless otherwise indicated) and were directly loaded on to the gel. Western blot analyses were performed by blotting SDS–PAGEs of the concentrations indicated on Hybond-P polyvinylidenfluorid filters (Amersham Biosciences, Uppsala, Sweden); polyclonal anti-Ssα-fuc antibodies from rabbit (PRIMM, Milan, Italy) and anti-GST antibodies (Amersham Biosciences) were diluted 1:5000 and 1:40 000, respectively. The filters were washed and incubated with the ImmunoPure anti-rabbit IgG antibody conjugated with the horseradish peroxidase (HRP) from Pierce Biotechnology (Rockford, IL, USA). Filters were developed with the ECL-plus Western Blotting Detection system (Amersham Biosciences) by following the manufacturer's indications. The molecular weight markers used in the western blot analyses were the ECL streptavidin–HRP conjugate (Amersham Biosciences). The protein concentration of the samples was measured with the method of Bradford (29) and the amounts of sample loaded on to the SDS–PAGEs are those indicated. The quantification of the bands identified by western blot was performed by using the program Quantity One 4.4.0 in a ChemiDoc EQ System (Bio-Rad, Hercules, CA, USA) with the volume analysis tool. The frameshifting efficiency was calculated as the ratio of the intensity of the bands of the frameshifted product/frameshifted product + termination product. The mutants in the slippery sequence of the wild-type gene fucA1 were prepared by site-directed mutagenesis from the vector pGEX-11867/3060, described previously (24,27). The synthetic oligonucleotides used (PRIMM) were the following: FucA1sm-rev, 5′-TTTAGGTGATATTGGTGTTCTGGTCTATCT-3′; FucA1sm-fwd, 5′-GAACACCAATATCACCTAAAGAATTCGGCCCA-3′; FucA1tm-rev, 5′-AGGTGATATTGGTGTTCTGGTCTATCTGGC-3′; FucA1tm-fwd, 5′-CCAGAACACCAATATCACCTCAAGAACTCGGCCCAGT-3′, where the mismatched nucleotides in the mutagenic primers are underlined. Direct sequencing identified the plasmids containing the desired mutations and the mutant genes, named fucA1sm and fucA1tm, were completely re-sequenced.\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[1].sections.sections[2].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a class object to represent papers/articles with contained methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "\n",
    "def normalize(words):\n",
    "    \n",
    "    out_words = [word.lower() for word in words if word not in stopwords]\n",
    "    \n",
    "    return out_words\n",
    "\n",
    "#######################################################################\n",
    "# Class method for representing Section\n",
    "#######################################################################\n",
    "\n",
    "# Section class encapsulates loading, displaying, and simple helper operations \n",
    "# e.g. return text or bag of words representation\n",
    "class Section:\n",
    "    # Initialize with key article fields from JSON object\n",
    "    # body_text (should preserve section type)\n",
    "    def __init__(self, json_object):#, label_map):\n",
    "        \n",
    "        #print(json_input)\n",
    "        \n",
    "        # Extract\n",
    "        self.type = json_object.get('section', '')\n",
    "        self.text= json_object.get('text', '')\n",
    "        self.normalized_text=normalize(self.text.split())\n",
    "        self.bow = set(self.normalized_text)\n",
    "        \n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "        \n",
    "        \n",
    "# Encapsulates list of sections, takes abstract and body_text JSON list \n",
    "# and generates subsections in order\n",
    "class Sections:\n",
    "    # Initialize with key article fields from JSON object\n",
    "    # body_text (should preserve section type)\n",
    "    def __init__(self, abstract=[], body_text=[]):#, label_map):\n",
    "        \n",
    "        self.sections=[]\n",
    "        \n",
    "        # Create a section from the abstract\n",
    "        if abstract:\n",
    "            self.sections.append(Section(abstract))\n",
    "        \n",
    "        # Iterate through the elements of the body_text and create sections, \n",
    "        # combining sequential items of the same type\n",
    "        if body_text:\n",
    "            current_type = ''\n",
    "            current_text = ''\n",
    "            delim_text = ''\n",
    "            for paragraph in body_text:\n",
    "                temp_type = paragraph.get('section', '')\n",
    "                temp_text = paragraph.get('text', '')\n",
    "                #print(temp_text)\n",
    "                if temp_type and temp_type != current_type:\n",
    "                    # Start new section\n",
    "                    self.sections.append(Section({'section': current_type, 'text': current_text}))\n",
    "                    current_type = temp_type\n",
    "                    current_text = temp_text\n",
    "                \n",
    "                # Continue adding to current section data\n",
    "                current_text += delim_text + temp_text\n",
    "                \n",
    "                if delim_text == '':\n",
    "                    delim_text = ' '\n",
    "                    \n",
    "            # If anything remaining, add section\n",
    "            if current_type or current_text:\n",
    "                self.sections.append(Section({'section': current_type, 'text': current_text}))\n",
    "        \n",
    "        # Extract\n",
    "        self.normalized_text=[]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sections:\n",
    "            yield s\n",
    "    \n",
    "    def get_text(self):\n",
    "        return '\\n'.join([s.get_text() for s in self.sections])\n",
    "        \n",
    "\n",
    "#######################################################################\n",
    "# Class method for representing Article (list of Sections)\n",
    "#######################################################################\n",
    "\n",
    "# Article class encapsulates loading, displaying, and simple helper operations \n",
    "# e.g. return text or bag of words representation\n",
    "class Article:\n",
    "    # Initialize with key article fields from JSON representation\n",
    "    # paper_id, title, authors, abstract, body_text, sections\n",
    "    def __init__(self, json_input):#, label_map):\n",
    "        \n",
    "        # Extract\n",
    "        self.paperID=json_object['paper_id'] #Paper ID\n",
    "        in_abs = json_object.get('abstract', {})\n",
    "        self.abstract=Section(in_abs)\n",
    "\n",
    "        self.sections = Sections(in_abs, json_object.get('body_text', []))\n",
    "\n",
    "    # \n",
    "    def get_text(self):\n",
    "        return self.sections.get_text()\n",
    "    \n",
    "    \n",
    "    #def get_bow(self, stopwords=[]):\n",
    "        #return self.card + ' ' + self.answer\n",
    "    \n",
    "    \n",
    "    # Add methods for running ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA methods below will take a list of docs where each is the unicode string including newlines etc. for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to larger dataset for better run now that it's debugged\n",
    "dir_path = '../noncomm_use_subset/pmc_json/'\n",
    "filename = 'PMC1616946.xml.json'\n",
    "\n",
    "print(os.listdir(dir_path))\n",
    "\n",
    "print(\"---------\" + dir_path + filename)\n",
    "print()\n",
    "\n",
    "articles = []\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "    filepath = dir_path + file\n",
    "    print(\"++---------\" + filepath)\n",
    "    with open(filepath, 'r') as infile:\n",
    "        json_object = json.load(infile)\n",
    "        #print(json.dumps(json_object, indent=2))\n",
    "        a = Article(json_object)\n",
    "        articles.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = []\n",
    "for a in articles:\n",
    "    sections.extend(a.sections)\n",
    "docs = [s.get_text() for s in sections]\n",
    "\n",
    "# Filter empty docs (sections)\n",
    "docs = [d for d in docs if d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The standard triplet readout of the genetic code can be reprogrammed by signals in the mRNA to induce ribosomal frameshifting [reviewed in (1–3)]. Generally, the resulting trans-frame protein product is functional and may in some cases be expressed in equal amounts to the product of standard translation. This elaboration of the genetic code (4,5) demonstrates versatility in decoding.The standard triplet readout of the genetic code can be reprogrammed by signals in the mRNA to induce ribosomal frameshifting [reviewed in (1–3)]. Generally, the resulting trans-frame protein product is functional and may in some cases be expressed in equal amounts to the product of standard translation. This elaboration of the genetic code (4,5) demonstrates versatility in decoding. Requirements for eukaryotic ribosomal frameshifting include a shift-prone sequence at the decoding site and often a downstream secondary structure in mRNA. The majority of −1 programmed frameshift sites consist of a heptanucleotide sequence X XXY YYZ [where X can be A, G, C or U; Y can be A or U; and Z can be any nucleotide (6)]. In this configuration, the P- and A-site tRNAs can re-pair with at least 2 out of 3 nt when shifted 1 nt towards the 5′ end of the mRNA. Similarly, for +1 frameshift sites, the identity of the codons in the P- and A-sites of the ribosome is critical for efficient frameshifting. One factor affecting +1 frameshift efficiency is the initial stability of the P-site tRNA–mRNA interaction in the 0 frame (7). High-efficiency frameshifting occurs when the P-site tRNA does not form standard codon–anticodon interactions (8). In some studies, a correlation between +1 frameshift efficiency and the final stability of the P-site tRNA–mRNA interaction in the +1 frame has been shown previously (9,10). However, in other systems there appears to be little correlation (11). In addition, competition between decoding of the 0 frame and +1 frame codons in the A-site may affect frameshifting efficiency (7). Slow to decode 0 frame codons such as stop codons or those decoded by low abundance tRNAs favor frameshifting, as do +1 frame codons with high levels of corresponding cognate tRNAs (12–16). High levels of frameshifting are often achieved by the stimulatory action of a cis-acting element located downstream of the shift site. A wide variety of structures, most commonly H-type pseudoknots (17), have been identified which stimulate −1 frameshifting in eukaryotes [for reviews see (18,19)]. Mutagenic and structural data for several of the frameshift stimulators have demonstrated that each pseudoknot has key structural features required for frameshift stimulation (20–28). However, unifying structural feature essential for frameshifting has not yet been identified. This observation combined with recent reports that simple antisense oligonucleotides can functionally mimic cis-acting 3′ stimulators of −1 frameshifting (29,30) demonstrates that many different structures can stimulate frameshifting. Although it should be noted that not all structures of equal thermodynamic stability can stimulate frameshifting (Discussion). RNA pseudoknots have also been shown to stimulate programmed +1 frameshifting in many eukaryotic antizyme genes (31,32). Antizyme is a negative regulator of cellular polyamine levels through its ability to target ornithine decarboxylase (the rate-limiting enzyme in polyamine biosynthesis) for degradation (33–35), inhibits polyamine import (36,37) and stimulates export (38). Antizyme expression is induced by high-intracellular polyamine levels, and decreased with lowered levels. The polyamine sensor is a programmed +1 frameshift event that is required for antizyme synthesis. At low polyamine levels, termination at the end of open reading frame 1 (ORF1) is efficient, whereas at high levels of polyamines, a substantial proportion of ribosomes shift to the +1 reading frame and then resume standard decoding to synthesize the full-length and active antizyme protein. Frameshifting at the mammalian antizyme mRNA shift site, UCC UGA, is stimulated by two cis-acting signals (39,40). One of these, the 5′ element, encompasses ∼50 bases upstream of shift site and is important for the polyamine effect (39–41). The other cis-acting element is a pseudoknot located 3′ of the shift site. The mammalian antizyme pseudoknot and a structurally distinct counterpart in a subset of invertebrate antizyme mRNAs (31) are the only pseudoknots known to act as stimulators for +1 frameshifting in eukaryotes. Although it is unknown if pseudoknots stimulate −1 frameshifting and +1 frameshifting by different mechanisms, one notable difference is found in positioning of the downstream structure relative to the shift site. Naturally occurring pseudoknots or stem–loop stimulators of −1 frameshifting typically begin ∼6–9 nt downstream of the A-site codon of the shift site (18), whereas +1 frameshift pseudoknots are located closer with only a 2–3 nt separation from the A-site codon (31). Mutagenic studies have revealed that altering the size of the spacer affects frameshifting and, in general, reduces efficiency (27,31,42–44). Here we have tested the ability of antisense oligonucleotides, annealed downstream of the shift-prone site, UCC UGA, to induce shifting of the ribosome to the +1 reading frame. The directionality of frameshifting (either into the +1 or −1 reading frame) is shown to be dependent upon the position of the duplex region relative to the shift site, and the efficiency of frameshifting is responsive to polyamine levels and enhanced by the inclusion of stimulatory sequences found upstream of the human antizyme +1 programmed frameshift site.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 2] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/pedro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import gensim # conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 22\n",
      "Number of documents: 53\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -0.7028.\n",
      "[([(0.23273917, 'gene'),\n",
      "   (0.115503564, 'sequence'),\n",
      "   (0.10922195, 'site'),\n",
      "   (0.08608394, 'mutant'),\n",
      "   (0.06438551, 'two'),\n",
      "   (0.06207177, 'wild_type'),\n",
      "   (0.06207177, 'wild'),\n",
      "   (0.061865572, 'type'),\n",
      "   (0.048662797, 'figure'),\n",
      "   (0.04844857, 'protein'),\n",
      "   (0.029689193, 'could'),\n",
      "   (0.028351704, 'which'),\n",
      "   (0.017382966, 'only'),\n",
      "   (0.0123550845, 'used'),\n",
      "   (0.011567903, 'these'),\n",
      "   (0.003582806, 'result'),\n",
      "   (0.003513739, 'using'),\n",
      "   (0.00075725775, 'have'),\n",
      "   (0.000601775, 'into'),\n",
      "   (0.00046981158, 'cell')],\n",
      "  -0.6637651146053567),\n",
      " ([(0.38496497, 'only'),\n",
      "   (0.30783033, 'result'),\n",
      "   (0.090352304, 'have'),\n",
      "   (0.08116736, 'these'),\n",
      "   (0.06413279, 'each'),\n",
      "   (0.051096015, 'into'),\n",
      "   (0.0012788294, 'gene'),\n",
      "   (0.0012788104, 'could'),\n",
      "   (0.0012787632, 'protein'),\n",
      "   (0.0012786003, 'which'),\n",
      "   (0.0012785437, 'sequence'),\n",
      "   (0.0012785094, 'using'),\n",
      "   (0.0012784905, 'used'),\n",
      "   (0.0012784789, 'rna'),\n",
      "   (0.0012784601, 'two'),\n",
      "   (0.0012784359, 'type'),\n",
      "   (0.0012783958, 'wild_type'),\n",
      "   (0.0012783958, 'wild'),\n",
      "   (0.0012783948, 'figure'),\n",
      "   (0.0012783797, 'site')],\n",
      "  -0.6733306295792256),\n",
      " ([(0.3969225, 'rna'),\n",
      "   (0.21958783, 'protein'),\n",
      "   (0.060073458, 'these'),\n",
      "   (0.04120614, 'two'),\n",
      "   (0.0339071, 'could'),\n",
      "   (0.03265478, 'into'),\n",
      "   (0.0317444, 'mutant'),\n",
      "   (0.03013312, 'cell'),\n",
      "   (0.029804293, 'figure'),\n",
      "   (0.025087332, 'have'),\n",
      "   (0.020003535, 'type'),\n",
      "   (0.014214055, 'which'),\n",
      "   (0.014182991, 'site'),\n",
      "   (0.013418022, 'using'),\n",
      "   (0.010215885, 'wild_type'),\n",
      "   (0.010215878, 'wild'),\n",
      "   (0.008812143, 'result'),\n",
      "   (0.004945671, 'only'),\n",
      "   (0.0018168824, 'gene'),\n",
      "   (0.00065516913, 'used')],\n",
      "  -0.6749472107643413),\n",
      " ([(0.313046, 'sequence'),\n",
      "   (0.12014583, 'have'),\n",
      "   (0.08334238, 'these'),\n",
      "   (0.07559964, 'which'),\n",
      "   (0.07185319, 'used'),\n",
      "   (0.058191475, 'only'),\n",
      "   (0.0516567, 'gene'),\n",
      "   (0.049576566, 'result'),\n",
      "   (0.04693755, 'into'),\n",
      "   (0.045376286, 'using'),\n",
      "   (0.02850638, 'each'),\n",
      "   (0.01844707, 'could'),\n",
      "   (0.012596227, 'rna'),\n",
      "   (0.008580047, 'protein'),\n",
      "   (0.008407778, 'type'),\n",
      "   (0.0048114923, 'two'),\n",
      "   (0.0009344073, 'site'),\n",
      "   (0.0005508002, 'figure'),\n",
      "   (0.00037085652, 'mutant'),\n",
      "   (0.00035640885, 'wild_type')],\n",
      "  -0.6931388135267457),\n",
      " ([(0.317812, 'cell'),\n",
      "   (0.19378616, 'mutant'),\n",
      "   (0.12017272, 'wild'),\n",
      "   (0.12017271, 'wild_type'),\n",
      "   (0.11693255, 'type'),\n",
      "   (0.106651336, 'figure'),\n",
      "   (0.011187436, 'each'),\n",
      "   (0.009539404, 'into'),\n",
      "   (0.00027654966, 'site'),\n",
      "   (0.00026693536, 'used'),\n",
      "   (0.0002668823, 'rna'),\n",
      "   (0.00026687625, 'protein'),\n",
      "   (0.00026686833, 'these'),\n",
      "   (0.00026686394, 'result'),\n",
      "   (0.00026686216, 'only'),\n",
      "   (0.0002668619, 'using'),\n",
      "   (0.00026685063, 'two'),\n",
      "   (0.00026684516, 'could'),\n",
      "   (0.00026682694, 'sequence'),\n",
      "   (0.00026682238, 'gene')],\n",
      "  -0.694385869170542),\n",
      " ([(0.39570603, 'site'),\n",
      "   (0.13472652, 'figure'),\n",
      "   (0.054295648, 'sequence'),\n",
      "   (0.05337943, 'have'),\n",
      "   (0.04754008, 'each'),\n",
      "   (0.0407378, 'which'),\n",
      "   (0.038474824, 'rna'),\n",
      "   (0.03823331, 'type'),\n",
      "   (0.032751683, 'wild_type'),\n",
      "   (0.032751683, 'wild'),\n",
      "   (0.02610595, 'two'),\n",
      "   (0.024976455, 'these'),\n",
      "   (0.023355031, 'into'),\n",
      "   (0.019236332, 'protein'),\n",
      "   (0.014651436, 'result'),\n",
      "   (0.01289335, 'only'),\n",
      "   (0.0061610225, 'could'),\n",
      "   (0.0016790592, 'gene'),\n",
      "   (0.0006215426, 'mutant'),\n",
      "   (0.00061911135, 'cell')],\n",
      "  -0.699671476357742),\n",
      " ([(0.19200048, 'used'),\n",
      "   (0.18934076, 'two'),\n",
      "   (0.11833624, 'into'),\n",
      "   (0.09542459, 'sequence'),\n",
      "   (0.07395894, 'figure'),\n",
      "   (0.06329101, 'have'),\n",
      "   (0.061302166, 'gene'),\n",
      "   (0.05234297, 'could'),\n",
      "   (0.050540816, 'only'),\n",
      "   (0.028057918, 'each'),\n",
      "   (0.02569462, 'these'),\n",
      "   (0.02205509, 'using'),\n",
      "   (0.013239722, 'which'),\n",
      "   (0.009540029, 'result'),\n",
      "   (0.00060936395, 'cell'),\n",
      "   (0.00060934416, 'site'),\n",
      "   (0.0006093385, 'protein'),\n",
      "   (0.0006093107, 'rna'),\n",
      "   (0.00060930126, 'mutant'),\n",
      "   (0.00060929783, 'wild_type')],\n",
      "  -0.7266894581278771),\n",
      " ([(0.37693265, 'using'),\n",
      "   (0.25729185, 'each'),\n",
      "   (0.22322345, 'used'),\n",
      "   (0.069863744, 'rna'),\n",
      "   (0.03558601, 'into'),\n",
      "   (0.022975978, 'result'),\n",
      "   (0.00088318443, 'gene'),\n",
      "   (0.00088301266, 'protein'),\n",
      "   (0.00088299735, 'cell'),\n",
      "   (0.0008829669, 'sequence'),\n",
      "   (0.0008829192, 'which'),\n",
      "   (0.0008829174, 'figure'),\n",
      "   (0.000882903, 'site'),\n",
      "   (0.00088287785, 'these'),\n",
      "   (0.00088284776, 'mutant'),\n",
      "   (0.0008828454, 'could'),\n",
      "   (0.0008828257, 'two'),\n",
      "   (0.0008828248, 'only'),\n",
      "   (0.0008828202, 'wild_type'),\n",
      "   (0.0008828202, 'wild')],\n",
      "  -0.7301411431196351),\n",
      " ([(0.19654849, 'figure'),\n",
      "   (0.19653898, 'which'),\n",
      "   (0.13654949, 'cell'),\n",
      "   (0.10800859, 'result'),\n",
      "   (0.07284467, 'gene'),\n",
      "   (0.06714329, 'protein'),\n",
      "   (0.06561494, 'these'),\n",
      "   (0.041020695, 'rna'),\n",
      "   (0.03305376, 'using'),\n",
      "   (0.031565078, 'could'),\n",
      "   (0.026905298, 'two'),\n",
      "   (0.017544331, 'used'),\n",
      "   (0.00066634227, 'type'),\n",
      "   (0.00066632614, 'only'),\n",
      "   (0.00066626276, 'have'),\n",
      "   (0.0006662544, 'into'),\n",
      "   (0.00066622806, 'each'),\n",
      "   (0.0006662266, 'site'),\n",
      "   (0.00066622486, 'wild'),\n",
      "   (0.0006662248, 'wild_type')],\n",
      "  -0.735235693114711),\n",
      " ([(0.04545456, 'rna'),\n",
      "   (0.045454558, 'cell'),\n",
      "   (0.04545455, 'site'),\n",
      "   (0.04545455, 'used'),\n",
      "   (0.04545455, 'figure'),\n",
      "   (0.04545455, 'protein'),\n",
      "   (0.045454547, 'mutant'),\n",
      "   (0.045454547, 'using'),\n",
      "   (0.045454547, 'each'),\n",
      "   (0.045454547, 'sequence'),\n",
      "   (0.045454543, 'gene'),\n",
      "   (0.045454543, 'result'),\n",
      "   (0.04545454, 'wild_type'),\n",
      "   (0.04545454, 'into'),\n",
      "   (0.04545454, 'wild'),\n",
      "   (0.04545454, 'which'),\n",
      "   (0.04545454, 'these'),\n",
      "   (0.04545454, 'type'),\n",
      "   (0.04545454, 'have'),\n",
      "   (0.04545454, 'could')],\n",
      "  -0.7364086299466901)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
